{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09-Normalization-and-regularization-solution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W38AS1bbMSAB"
      },
      "source": [
        "# Normalization and regularization techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRvEGyli-o16"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "We will experiment with [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) data set. It is similar to well known MNIST data set but a bit more difficult to classify. It consists of clothing classes. The data is already shuffled and split to train and test parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffslWOEb-pmu",
        "outputId": "d9bae0eb-0d2b-4783-e799-1a56653a633a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import pickle\n",
        "from tensorflow.python.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(\"X_train original shape: {}\".format(X_train.shape))\n",
        "print(\"y_train original shape: {}\".format(y_train.shape))\n",
        "print(\"X_test original shape: {}\".format(X_test.shape))\n",
        "print(\"y_test original shape: {}\".format(y_test.shape))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train original shape: (60000, 28, 28)\n",
            "y_train original shape: (60000,)\n",
            "X_test original shape: (10000, 28, 28)\n",
            "y_test original shape: (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm92Tbbi-ySC"
      },
      "source": [
        "Look at one random example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVelrCku-uiR",
        "outputId": "1d21da1a-92ca-426d-87cc-71e355ca034c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "i=3495\n",
        "\n",
        "#print(X_train[i])\n",
        "plt.imshow(X_train[i], cmap='gray')\n",
        "plt.title(\"Class {}\".format(y_train[i]))\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wIkgz7X-44q"
      },
      "source": [
        "## Transform the data\n",
        "\n",
        "We need to scale the input values to have the range (0,1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo58moqt-0r0"
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGM3Camr_D5l"
      },
      "source": [
        "Reshape to 3d tensors (width, height, channels)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RntHN3GZ_EWA",
        "outputId": "f9f022ba-146f-4f38-fc54-63a54324c270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train3d = X_train.reshape(60000, 28, 28, 1)\n",
        "X_test3d = X_test.reshape(10000, 28, 28, 1)\n",
        "print(\"X_train matrix shape: {}\".format(X_train3d.shape))\n",
        "print(\"X_test matrix shape: {}\".format(X_test3d.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train matrix shape: (60000, 28, 28, 1)\n",
            "X_test matrix shape: (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jaa13K4_LWy"
      },
      "source": [
        "Transform the targets into one-hot encoding, i.e.\n",
        "\n",
        "\n",
        "```\n",
        "0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "```\n",
        "etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEuuEd5N_GhB",
        "outputId": "c41c3c2c-9cf9-440e-caac-c5ceed1062ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from tensorflow.python.keras.utils import np_utils\n",
        "\n",
        "n_classes = 10\n",
        "\n",
        "print(y_train[49])\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "\n",
        "print(y_train[49])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ_yK58i_Ucc"
      },
      "source": [
        "## Architecture definition\n",
        "\n",
        "This is a simple functional model for the classification problem. Your tasks are:\n",
        "1. Implement [Batch](https://keras.io/api/layers/normalization_layers/batch_normalization/) and [Layer](https://keras.io/api/layers/normalization_layers/layer_normalization/) normalization and compare the accuracies.\n",
        "2. Experiment with [L2 regularization](https://keras.io/api/layers/regularizers/) and [dropout](https://keras.io/api/layers/regularization_layers/dropout/). Try to maximize the validation accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mISOO8tQ_ved"
      },
      "source": [
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.layers import Input, BatchNormalization, Flatten, Dropout, Dense, Activation, BatchNormalization, LayerNormalization\n",
        "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "\n",
        "#Define input of the Neural Network\n",
        "visible = Input(shape=(28, 28, 1, ))\n",
        "\n",
        "#convolution 1st layer\n",
        "conv1 = Conv2D(64, kernel_size=(3,3), padding=\"same\")(visible)\n",
        "activ1 = Activation('relu')(conv1)\n",
        "bn1 = BatchNormalization()(activ1)\n",
        "drop1 = Dropout(0.25)(bn1)\n",
        "\n",
        "#convolution 2nd layer\n",
        "conv2 = Conv2D(64, kernel_size=(3,3), padding=\"same\")(drop1)\n",
        "activ2 = Activation('relu')(conv2)\n",
        "bn2 = BatchNormalization()(activ2)\n",
        "pool2 = MaxPooling2D()(bn2)\n",
        "drop2 = Dropout(0.25)(pool2)\n",
        "\n",
        "#convolution 3rd layer\n",
        "conv3 = Conv2D(64, kernel_size=(3,3), padding=\"same\")(drop2)\n",
        "activ3 = Activation('relu')(conv3)\n",
        "bn3 = BatchNormalization()(activ3)\n",
        "pool3 = MaxPooling2D()(bn3)\n",
        "drop3 = Dropout(0.25)(pool3)\n",
        "\n",
        "#fully connected 4th layer\n",
        "flat4 = Flatten()(drop3)\n",
        "dense4 = Dense(500)(flat4)\n",
        "bn4 = BatchNormalization()(dense4)\n",
        "activ4 = Activation('relu')(bn4)\n",
        "drop4 = Dropout(0.25)(activ4)\n",
        "  \n",
        "#fully connected 5th layer\n",
        "dense5 = Dense(10)(drop4)\n",
        "output = Activation('softmax')(dense5)\n",
        "\n",
        "model = Model(inputs=visible, outputs=output)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMvSl5erbuEg"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "#print(model.summary())\n",
        "#plot_model(model)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBwd1WqbO03N"
      },
      "source": [
        "Compile and the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5ux0mm1_2VO"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrmhiUZfAIOy",
        "outputId": "b4389784-1adc-4cf7-b12c-57cdceb382a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train3d, y_train,\n",
        "          batch_size = 128, epochs = 100, verbose=1,\n",
        "          validation_data=(X_test3d, y_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.3948 - accuracy: 0.8555 - val_loss: 1.0216 - val_accuracy: 0.6401\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.2608 - accuracy: 0.9036 - val_loss: 0.2490 - val_accuracy: 0.9090\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.2235 - accuracy: 0.9184 - val_loss: 0.2111 - val_accuracy: 0.9239\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1989 - accuracy: 0.9272 - val_loss: 0.2041 - val_accuracy: 0.9253\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1799 - accuracy: 0.9334 - val_loss: 0.2169 - val_accuracy: 0.9199\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1640 - accuracy: 0.9389 - val_loss: 0.2058 - val_accuracy: 0.9250\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1501 - accuracy: 0.9438 - val_loss: 0.1922 - val_accuracy: 0.9332\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1365 - accuracy: 0.9485 - val_loss: 0.1894 - val_accuracy: 0.9336\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1270 - accuracy: 0.9535 - val_loss: 0.1940 - val_accuracy: 0.9343\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1161 - accuracy: 0.9563 - val_loss: 0.1917 - val_accuracy: 0.9343\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1040 - accuracy: 0.9615 - val_loss: 0.1893 - val_accuracy: 0.9357\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0989 - accuracy: 0.9633 - val_loss: 0.1986 - val_accuracy: 0.9336\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0931 - accuracy: 0.9653 - val_loss: 0.1990 - val_accuracy: 0.9339\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0856 - accuracy: 0.9675 - val_loss: 0.2017 - val_accuracy: 0.9325\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0789 - accuracy: 0.9711 - val_loss: 0.2054 - val_accuracy: 0.9332\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0725 - accuracy: 0.9738 - val_loss: 0.2174 - val_accuracy: 0.9341\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0667 - accuracy: 0.9753 - val_loss: 0.2143 - val_accuracy: 0.9339\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.0646 - accuracy: 0.9758 - val_loss: 0.2095 - val_accuracy: 0.9377\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0593 - accuracy: 0.9779 - val_loss: 0.2171 - val_accuracy: 0.9362\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0575 - accuracy: 0.9788 - val_loss: 0.2136 - val_accuracy: 0.9366\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0520 - accuracy: 0.9809 - val_loss: 0.2196 - val_accuracy: 0.9376\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0518 - accuracy: 0.9815 - val_loss: 0.2157 - val_accuracy: 0.9394\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0480 - accuracy: 0.9823 - val_loss: 0.2219 - val_accuracy: 0.9386\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0446 - accuracy: 0.9835 - val_loss: 0.2115 - val_accuracy: 0.9385\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0435 - accuracy: 0.9844 - val_loss: 0.2295 - val_accuracy: 0.9409\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0405 - accuracy: 0.9855 - val_loss: 0.2335 - val_accuracy: 0.9367\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0397 - accuracy: 0.9857 - val_loss: 0.2248 - val_accuracy: 0.9401\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0389 - accuracy: 0.9858 - val_loss: 0.2443 - val_accuracy: 0.9375\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0348 - accuracy: 0.9871 - val_loss: 0.2411 - val_accuracy: 0.9380\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0345 - accuracy: 0.9876 - val_loss: 0.2428 - val_accuracy: 0.9430\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0334 - accuracy: 0.9879 - val_loss: 0.2499 - val_accuracy: 0.9382\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0352 - accuracy: 0.9872 - val_loss: 0.2420 - val_accuracy: 0.9415\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0325 - accuracy: 0.9886 - val_loss: 0.2508 - val_accuracy: 0.9410\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0299 - accuracy: 0.9892 - val_loss: 0.2500 - val_accuracy: 0.9373\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0301 - accuracy: 0.9898 - val_loss: 0.2597 - val_accuracy: 0.9393\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0306 - accuracy: 0.9892 - val_loss: 0.2536 - val_accuracy: 0.9394\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0287 - accuracy: 0.9899 - val_loss: 0.2565 - val_accuracy: 0.9390\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0282 - accuracy: 0.9899 - val_loss: 0.2580 - val_accuracy: 0.9395\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0274 - accuracy: 0.9903 - val_loss: 0.2469 - val_accuracy: 0.9384\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0260 - accuracy: 0.9905 - val_loss: 0.2718 - val_accuracy: 0.9353\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0245 - accuracy: 0.9914 - val_loss: 0.2607 - val_accuracy: 0.9382\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.2699 - val_accuracy: 0.9370\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0248 - accuracy: 0.9914 - val_loss: 0.2761 - val_accuracy: 0.9371\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0244 - accuracy: 0.9915 - val_loss: 0.2952 - val_accuracy: 0.9361\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0232 - accuracy: 0.9913 - val_loss: 0.2681 - val_accuracy: 0.9409\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.2609 - val_accuracy: 0.9393\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0229 - accuracy: 0.9920 - val_loss: 0.2684 - val_accuracy: 0.9379\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0238 - accuracy: 0.9914 - val_loss: 0.2679 - val_accuracy: 0.9397\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0225 - accuracy: 0.9920 - val_loss: 0.2639 - val_accuracy: 0.9422\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0224 - accuracy: 0.9923 - val_loss: 0.2768 - val_accuracy: 0.9372\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0206 - accuracy: 0.9926 - val_loss: 0.2842 - val_accuracy: 0.9368\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0202 - accuracy: 0.9929 - val_loss: 0.2847 - val_accuracy: 0.9369\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0209 - accuracy: 0.9925 - val_loss: 0.2834 - val_accuracy: 0.9377\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0188 - accuracy: 0.9930 - val_loss: 0.2898 - val_accuracy: 0.9415\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.2695 - val_accuracy: 0.9402\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0184 - accuracy: 0.9936 - val_loss: 0.3339 - val_accuracy: 0.9356\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0178 - accuracy: 0.9933 - val_loss: 0.2908 - val_accuracy: 0.9412\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0187 - accuracy: 0.9936 - val_loss: 0.2948 - val_accuracy: 0.9384\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0172 - accuracy: 0.9941 - val_loss: 0.2795 - val_accuracy: 0.9396\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.3017 - val_accuracy: 0.9407\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 0.2980 - val_accuracy: 0.9392\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0170 - accuracy: 0.9938 - val_loss: 0.2851 - val_accuracy: 0.9397\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0180 - accuracy: 0.9936 - val_loss: 0.2786 - val_accuracy: 0.9403\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.2919 - val_accuracy: 0.9365\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0171 - accuracy: 0.9940 - val_loss: 0.2883 - val_accuracy: 0.9393\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.2982 - val_accuracy: 0.9375\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0160 - accuracy: 0.9942 - val_loss: 0.2827 - val_accuracy: 0.9401\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.2976 - val_accuracy: 0.9403\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.2832 - val_accuracy: 0.9393\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 0.2943 - val_accuracy: 0.9376\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 0.3064 - val_accuracy: 0.9388\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0169 - accuracy: 0.9941 - val_loss: 0.3014 - val_accuracy: 0.9371\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.2976 - val_accuracy: 0.9397\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.3367 - val_accuracy: 0.9376\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.3098 - val_accuracy: 0.9368\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.3090 - val_accuracy: 0.9381\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.3052 - val_accuracy: 0.9386\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.2985 - val_accuracy: 0.9394\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.3120 - val_accuracy: 0.9395\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.3397 - val_accuracy: 0.9365\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.3030 - val_accuracy: 0.9399\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.3056 - val_accuracy: 0.9414\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 0.3184 - val_accuracy: 0.9408\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.3234 - val_accuracy: 0.9398\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.3083 - val_accuracy: 0.9374\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.3129 - val_accuracy: 0.9387\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.3090 - val_accuracy: 0.9389\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.3139 - val_accuracy: 0.9387\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.3037 - val_accuracy: 0.9389\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.2973 - val_accuracy: 0.9385\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.3446 - val_accuracy: 0.9372\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.3043 - val_accuracy: 0.9387\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0127 - accuracy: 0.9955 - val_loss: 0.2931 - val_accuracy: 0.9415\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.3093 - val_accuracy: 0.9409\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.3078 - val_accuracy: 0.9413\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.3186 - val_accuracy: 0.9386\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.3317 - val_accuracy: 0.9405\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.3340 - val_accuracy: 0.9386\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.3358 - val_accuracy: 0.9400\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.3229 - val_accuracy: 0.9403\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f02ebf55d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}