{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09-Normalization-and-regularization-solution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W38AS1bbMSAB"
      },
      "source": [
        "# Normalization and regularization techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRvEGyli-o16"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "We will experiment with [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) data set. It is similar to well known MNIST data set but a bit more difficult to classify. It consists of clothing classes. The data is already shuffled and split to train and test parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffslWOEb-pmu",
        "outputId": "d8d9f3b6-cc7d-454b-9001-ded8cdbe34bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import pickle\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(\"X_train original shape: {}\".format(X_train.shape))\n",
        "print(\"y_train original shape: {}\".format(y_train.shape))\n",
        "print(\"X_test original shape: {}\".format(X_test.shape))\n",
        "print(\"y_test original shape: {}\".format(y_test.shape))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train original shape: (60000, 28, 28)\n",
            "y_train original shape: (60000,)\n",
            "X_test original shape: (10000, 28, 28)\n",
            "y_test original shape: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm92Tbbi-ySC"
      },
      "source": [
        "Look at one random example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVelrCku-uiR",
        "outputId": "89043a2a-2a35-4445-ef5d-5424f7321d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "i=3495\n",
        "\n",
        "#print(X_train[i])\n",
        "plt.imshow(X_train[i], cmap='gray')\n",
        "plt.title(\"Class {}\".format(y_train[i]))\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wIkgz7X-44q"
      },
      "source": [
        "## Transform the data\n",
        "\n",
        "We need to scale the input values to have the range (0,1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo58moqt-0r0"
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGM3Camr_D5l"
      },
      "source": [
        "Reshape to 3d tensors (width, height, channels)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RntHN3GZ_EWA",
        "outputId": "22c2c93d-c4ab-4993-acdb-9a0c729653ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train3d = X_train.reshape(60000, 28, 28, 1)\n",
        "X_test3d = X_test.reshape(10000, 28, 28, 1)\n",
        "print(\"X_train matrix shape: {}\".format(X_train3d.shape))\n",
        "print(\"X_test matrix shape: {}\".format(X_test3d.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train matrix shape: (60000, 28, 28, 1)\n",
            "X_test matrix shape: (10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jaa13K4_LWy"
      },
      "source": [
        "Transform the targets into one-hot encoding, i.e.\n",
        "\n",
        "\n",
        "```\n",
        "0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "```\n",
        "etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEuuEd5N_GhB",
        "outputId": "4e2cd4ac-8719-4d64-92ba-8b99a59a1884",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "n_classes = 10\n",
        "\n",
        "print(y_train[49])\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "\n",
        "print(y_train[49])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ_yK58i_Ucc"
      },
      "source": [
        "## Architecture definition\n",
        "\n",
        "This is a simple functional model for the classification problem. Your tasks are:\n",
        "1. Implement [Batch](https://keras.io/api/layers/normalization_layers/batch_normalization/) and [Layer](https://keras.io/api/layers/normalization_layers/layer_normalization/) normalization and compare the accuracies.\n",
        "2. Experiment with [L2 regularization](https://keras.io/api/layers/regularizers/) and [dropout](https://keras.io/api/layers/regularization_layers/dropout/). Try to maximize the validation accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mISOO8tQ_ved"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, BatchNormalization, Flatten, Dropout, Dense, Activation, BatchNormalization, LayerNormalization\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "\n",
        "#Define input of the Neural Network\n",
        "visible = Input(shape=(28, 28, 1, ))\n",
        "\n",
        "#convolution 1st layer\n",
        "conv1 = Conv2D(64, kernel_size=(3,3), padding=\"same\")(visible)\n",
        "activ1 = Activation('relu')(conv1)\n",
        "bn1 = BatchNormalization()(activ1)\n",
        "drop1 = Dropout(0.25)(bn1)\n",
        "\n",
        "#convolution 2nd layer\n",
        "conv2 = Conv2D(64, kernel_size=(3,3), padding=\"same\")(drop1)\n",
        "activ2 = Activation('relu')(conv2)\n",
        "bn2 = BatchNormalization()(activ2)\n",
        "pool2 = MaxPooling2D()(bn2)\n",
        "drop2 = Dropout(0.25)(pool2)\n",
        "\n",
        "#convolution 3rd layer\n",
        "conv3 = Conv2D(64, kernel_size=(3,3), padding=\"same\")(drop2)\n",
        "activ3 = Activation('relu')(conv3)\n",
        "bn3 = BatchNormalization()(activ3)\n",
        "pool3 = MaxPooling2D()(bn3)\n",
        "drop3 = Dropout(0.25)(pool3)\n",
        "\n",
        "#fully connected 4th layer\n",
        "flat4 = Flatten()(drop3)\n",
        "dense4 = Dense(500)(flat4)\n",
        "bn4 = BatchNormalization()(dense4)\n",
        "activ4 = Activation('relu')(bn4)\n",
        "drop4 = Dropout(0.25)(activ4)\n",
        "  \n",
        "#fully connected 5th layer\n",
        "dense5 = Dense(10)(drop4)\n",
        "output = Activation('softmax')(dense5)\n",
        "\n",
        "model = Model(inputs=visible, outputs=output)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMvSl5erbuEg"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "#print(model.summary())\n",
        "#plot_model(model)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBwd1WqbO03N"
      },
      "source": [
        "Compile and the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5ux0mm1_2VO"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrmhiUZfAIOy",
        "outputId": "fbeb2b77-c5c8-4807-ce5d-45da1761271b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train3d, y_train,\n",
        "          batch_size = 128, epochs = 100, verbose=1,\n",
        "          validation_data=(X_test3d, y_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 30s 35ms/step - loss: 0.3949 - accuracy: 0.8551 - val_loss: 1.3771 - val_accuracy: 0.5928\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.2569 - accuracy: 0.9057 - val_loss: 0.2343 - val_accuracy: 0.9124\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.2202 - accuracy: 0.9181 - val_loss: 0.2401 - val_accuracy: 0.9139\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.1960 - accuracy: 0.9283 - val_loss: 0.2317 - val_accuracy: 0.9175\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.1784 - accuracy: 0.9343 - val_loss: 0.2002 - val_accuracy: 0.9288\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.1637 - accuracy: 0.9395 - val_loss: 0.2125 - val_accuracy: 0.9222\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.1497 - accuracy: 0.9441 - val_loss: 0.2008 - val_accuracy: 0.9291\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.1352 - accuracy: 0.9499 - val_loss: 0.2045 - val_accuracy: 0.9290\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.1241 - accuracy: 0.9529 - val_loss: 0.1956 - val_accuracy: 0.9304\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.1152 - accuracy: 0.9567 - val_loss: 0.1944 - val_accuracy: 0.9325\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.1073 - accuracy: 0.9590 - val_loss: 0.2004 - val_accuracy: 0.9336\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0954 - accuracy: 0.9648 - val_loss: 0.1980 - val_accuracy: 0.9365\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0895 - accuracy: 0.9664 - val_loss: 0.2048 - val_accuracy: 0.9354\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0829 - accuracy: 0.9686 - val_loss: 0.2024 - val_accuracy: 0.9373\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 16s 35ms/step - loss: 0.0773 - accuracy: 0.9715 - val_loss: 0.2114 - val_accuracy: 0.9366\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0717 - accuracy: 0.9734 - val_loss: 0.2091 - val_accuracy: 0.9368\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0679 - accuracy: 0.9746 - val_loss: 0.2112 - val_accuracy: 0.9373\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 16s 35ms/step - loss: 0.0623 - accuracy: 0.9764 - val_loss: 0.2258 - val_accuracy: 0.9327\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0586 - accuracy: 0.9786 - val_loss: 0.2386 - val_accuracy: 0.9301\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0530 - accuracy: 0.9807 - val_loss: 0.2329 - val_accuracy: 0.9362\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 16s 35ms/step - loss: 0.0515 - accuracy: 0.9818 - val_loss: 0.2196 - val_accuracy: 0.9353\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0497 - accuracy: 0.9820 - val_loss: 0.2328 - val_accuracy: 0.9362\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0463 - accuracy: 0.9831 - val_loss: 0.2368 - val_accuracy: 0.9384\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0440 - accuracy: 0.9839 - val_loss: 0.2550 - val_accuracy: 0.9351\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0443 - accuracy: 0.9841 - val_loss: 0.2397 - val_accuracy: 0.9350\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0404 - accuracy: 0.9856 - val_loss: 0.2387 - val_accuracy: 0.9368\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0391 - accuracy: 0.9859 - val_loss: 0.2280 - val_accuracy: 0.9391\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0388 - accuracy: 0.9864 - val_loss: 0.2615 - val_accuracy: 0.9361\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0367 - accuracy: 0.9869 - val_loss: 0.2487 - val_accuracy: 0.9366\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0346 - accuracy: 0.9876 - val_loss: 0.2515 - val_accuracy: 0.9357\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0349 - accuracy: 0.9878 - val_loss: 0.2744 - val_accuracy: 0.9311\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0335 - accuracy: 0.9885 - val_loss: 0.2484 - val_accuracy: 0.9382\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0312 - accuracy: 0.9892 - val_loss: 0.2738 - val_accuracy: 0.9301\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0305 - accuracy: 0.9891 - val_loss: 0.2630 - val_accuracy: 0.9365\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0284 - accuracy: 0.9903 - val_loss: 0.2435 - val_accuracy: 0.9380\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0287 - accuracy: 0.9898 - val_loss: 0.2617 - val_accuracy: 0.9383\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 0.2737 - val_accuracy: 0.9373\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0264 - accuracy: 0.9910 - val_loss: 0.2551 - val_accuracy: 0.9389\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 0.2686 - val_accuracy: 0.9397\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0248 - accuracy: 0.9911 - val_loss: 0.2758 - val_accuracy: 0.9397\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.2993 - val_accuracy: 0.9350\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0239 - accuracy: 0.9914 - val_loss: 0.2509 - val_accuracy: 0.9400\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0256 - accuracy: 0.9913 - val_loss: 0.2526 - val_accuracy: 0.9393\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0246 - accuracy: 0.9912 - val_loss: 0.2640 - val_accuracy: 0.9413\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0224 - accuracy: 0.9919 - val_loss: 0.2690 - val_accuracy: 0.9404\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 0.2872 - val_accuracy: 0.9420\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0211 - accuracy: 0.9927 - val_loss: 0.2833 - val_accuracy: 0.9380\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 0.2798 - val_accuracy: 0.9392\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.2702 - val_accuracy: 0.9386\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0222 - accuracy: 0.9922 - val_loss: 0.2780 - val_accuracy: 0.9392\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0199 - accuracy: 0.9929 - val_loss: 0.2963 - val_accuracy: 0.9399\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.2906 - val_accuracy: 0.9417\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 0.2797 - val_accuracy: 0.9407\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0195 - accuracy: 0.9934 - val_loss: 0.2939 - val_accuracy: 0.9386\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.3177 - val_accuracy: 0.9350\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0206 - accuracy: 0.9929 - val_loss: 0.2823 - val_accuracy: 0.9408\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.2902 - val_accuracy: 0.9373\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.2944 - val_accuracy: 0.9388\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.2899 - val_accuracy: 0.9364\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.2944 - val_accuracy: 0.9389\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 16s 35ms/step - loss: 0.0187 - accuracy: 0.9935 - val_loss: 0.3024 - val_accuracy: 0.9368\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 16s 35ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.3073 - val_accuracy: 0.9380\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 0.2859 - val_accuracy: 0.9374\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.3023 - val_accuracy: 0.9383\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.2825 - val_accuracy: 0.9402\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0171 - accuracy: 0.9938 - val_loss: 0.2997 - val_accuracy: 0.9388\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.3080 - val_accuracy: 0.9399\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.3072 - val_accuracy: 0.9383\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0144 - accuracy: 0.9950 - val_loss: 0.3088 - val_accuracy: 0.9408\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.3201 - val_accuracy: 0.9380\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.3028 - val_accuracy: 0.9395\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.3047 - val_accuracy: 0.9384\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.3285 - val_accuracy: 0.9378\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.3165 - val_accuracy: 0.9397\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.3037 - val_accuracy: 0.9402\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0135 - accuracy: 0.9952 - val_loss: 0.3251 - val_accuracy: 0.9399\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.3719 - val_accuracy: 0.9299\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.3121 - val_accuracy: 0.9403\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.3087 - val_accuracy: 0.9411\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 0.3266 - val_accuracy: 0.9393\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.3007 - val_accuracy: 0.9407\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.3272 - val_accuracy: 0.9393\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.3370 - val_accuracy: 0.9406\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.3114 - val_accuracy: 0.9387\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.3203 - val_accuracy: 0.9387\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.3336 - val_accuracy: 0.9389\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.3369 - val_accuracy: 0.9401\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.3308 - val_accuracy: 0.9398\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.3169 - val_accuracy: 0.9399\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.3191 - val_accuracy: 0.9383\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.3479 - val_accuracy: 0.9358\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.3244 - val_accuracy: 0.9407\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.3512 - val_accuracy: 0.9374\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.3316 - val_accuracy: 0.9390\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 15s 33ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.3437 - val_accuracy: 0.9387\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.3325 - val_accuracy: 0.9384\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.3314 - val_accuracy: 0.9421\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 16s 34ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.3226 - val_accuracy: 0.9374\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.3341 - val_accuracy: 0.9374\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 16s 33ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.3531 - val_accuracy: 0.9366\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8a30201410>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}