{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "17-Explainability-assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFj9vKMnYsvu"
      },
      "source": [
        "# Convolutional Neural Network Explainability on **MNIST**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMWzadigYsvx"
      },
      "source": [
        "## MNIST classification task\n",
        "\n",
        "The MNIST data set is a database of handwritten digits that is commonly used for training various image processing systems. The goal if this task is to implement a classifier of handwritten digits using neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCodqoi3Ysvy"
      },
      "source": [
        "![Mnist data set](https://github.com/jirimaterna/image-processing-2days/blob/master/images/mnist-examples.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnbUUb8NYsvy"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "The data is already shuffled and split to train and test parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjQRPjiyYsvz",
        "outputId": "44b0637e-4004-4af9-e87a-6be84a869482",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import pickle\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"X_train original shape: {}\".format(X_train.shape))\n",
        "print(\"y_train original shape: {}\".format(y_train.shape))\n",
        "print(\"X_test original shape: {}\".format(X_test.shape))\n",
        "print(\"y_test original shape: {}\".format(y_test.shape))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train original shape: (60000, 28, 28)\n",
            "y_train original shape: (60000,)\n",
            "X_test original shape: (10000, 28, 28)\n",
            "y_test original shape: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nv520izYsv4"
      },
      "source": [
        "## Transform the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIHRAFdyYsv5"
      },
      "source": [
        "We need to scale the input values to have the range (0,1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s_pCongYsv6"
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rr7O6ZCYsv8",
        "outputId": "ecb0ab5f-d12f-4bb3-bd44-d42cfff2a5c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train = X_train.reshape(60000, 28, 28, 1)\n",
        "X_test = X_test.reshape(10000, 28, 28, 1)\n",
        "print(\"X_train matrix shape: {}\".format(X_train.shape))\n",
        "print(\"X_test matrix shape: {}\".format(X_test.shape))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train matrix shape: (60000, 28, 28, 1)\n",
            "X_test matrix shape: (10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dzQVa-MYsv-"
      },
      "source": [
        "Transform the targets into one-hot encoding, i.e.\n",
        "```\n",
        "0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "```\n",
        "etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0xWKgl4Ysv-"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "n_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "y_test = np_utils.to_categorical(y_test, n_classes)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9D5zj9AYswb"
      },
      "source": [
        "## Architecture definition\n",
        "\n",
        "Create a sequential model and define its structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkgtiwi3Yswc",
        "outputId": "813cc0be-901c-47b5-ac6f-a1ec66ad916c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(5, 5), input_shape=(28, 28, 1, ), name='conv1_layer'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, kernel_size=(5, 5),  name='conv2_layer'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, name='last_layer'))\n",
        "model.add(Activation('softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1_layer (Conv2D)        (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 24, 24, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2_layer (Conv2D)        (None, 8, 8, 32)          25632     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 4, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " last_layer (Dense)          (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,594\n",
            "Trainable params: 31,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKgIKDT9Yswf"
      },
      "source": [
        "Compile the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeKXll35Yswf"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beZ8zNtpYswh"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJD1uf0iYswh",
        "outputId": "b6366c7f-e29a-455c-df0a-44044d0e0923",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size = 128, epochs = 10, verbose=1,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 9s 16ms/step - loss: 0.2718 - accuracy: 0.9193 - val_loss: 0.0758 - val_accuracy: 0.9775\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.0769 - accuracy: 0.9771 - val_loss: 0.0533 - val_accuracy: 0.9824\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.0563 - accuracy: 0.9830 - val_loss: 0.0516 - val_accuracy: 0.9825\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.0453 - accuracy: 0.9862 - val_loss: 0.0430 - val_accuracy: 0.9856\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.0374 - accuracy: 0.9883 - val_loss: 0.0354 - val_accuracy: 0.9885\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 0.0302 - val_accuracy: 0.9892\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.0270 - accuracy: 0.9914 - val_loss: 0.0283 - val_accuracy: 0.9895\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 0.0265 - val_accuracy: 0.9906\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 0.0298 - val_accuracy: 0.9897\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.0266 - val_accuracy: 0.9900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65d0273d10>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfXbZrbSYswj"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxMB2C2WYswk"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "y_test_class = np.argmax(y_test, axis=1)\n",
        "y_pred_class = np.argmax(y_pred, axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu-A_4YYYswm",
        "outputId": "1afd2900-755b-409f-d1a2-a0a468e35af2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (\"Test accuracy: {:.4f}\".format(accuracy_score(y_test_class, y_pred_class)))\n",
        "print ()\n",
        "print(classification_report(y_test_class, y_pred_class, digits=4))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9900\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9959    0.9878    0.9918       980\n",
            "           1     0.9956    0.9930    0.9943      1135\n",
            "           2     0.9875    0.9932    0.9903      1032\n",
            "           3     0.9930    0.9901    0.9916      1010\n",
            "           4     0.9919    0.9939    0.9929       982\n",
            "           5     0.9887    0.9832    0.9859       892\n",
            "           6     0.9845    0.9916    0.9880       958\n",
            "           7     0.9855    0.9932    0.9893      1028\n",
            "           8     0.9867    0.9897    0.9882       974\n",
            "           9     0.9900    0.9832    0.9866      1009\n",
            "\n",
            "    accuracy                         0.9900     10000\n",
            "   macro avg     0.9899    0.9899    0.9899     10000\n",
            "weighted avg     0.9900    0.9900    0.9900     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wdf_ZnviMam"
      },
      "source": [
        "## Activation Maximization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZWpbzN7BpQX"
      },
      "source": [
        "Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUEeG5kpl2DA"
      },
      "source": [
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ612YJABwmw"
      },
      "source": [
        "## Visualize activations of the classification layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y43-BS9BumQD"
      },
      "source": [
        "layer = model.get_layer(name=\"last_layer\")\n",
        "feature_extractor = Model(inputs=model.inputs, outputs=layer.output)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksDEIIX9b9HN"
      },
      "source": [
        "#define the loss function\n",
        "def compute_loss(input_image, filter_index, model):\n",
        "    activation = model(input_image)\n",
        "    filter_activation = activation[..., filter_index]\n",
        "    return tf.reduce_mean(filter_activation)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpdBZRqfsNkQ"
      },
      "source": [
        "#define one learning step\n",
        "import tensorflow as tf\n",
        "@tf.function\n",
        "def learning_step(img, filter_index, model, learning_rate):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(img)\n",
        "        loss = compute_loss(img, filter_index, model)\n",
        "    # Compute gradients.\n",
        "    grads = tape.gradient(loss, img)\n",
        "    # Normalize gradients.\n",
        "    grads = tf.math.l2_normalize(grads)\n",
        "    img += learning_rate * grads\n",
        "    return loss, img"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bs-Am1UsUDp"
      },
      "source": [
        "# We start from a gray image with some random noise\n",
        "def initialize_image():\n",
        "    img = tf.random.uniform((1, 28, 28, 1)) * 0.25\n",
        "    return img"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mH_elCCTRPs"
      },
      "source": [
        "def deprocess_image(img):\n",
        "    img -= img.mean()\n",
        "    img /= img.std() + 1e-5\n",
        "    img *= 0.15\n",
        "    img = np.clip(img, 0, 1)\n",
        "    img *= 255\n",
        "    img = -np.clip(img, 0, 255).astype(\"uint8\") + 255\n",
        "    return img"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za4AY2k7s7ku"
      },
      "source": [
        "# Run the training algorithm\n",
        "def visualize_filter(filter_index, model):\n",
        "    iterations = 100\n",
        "    learning_rate = 10.0\n",
        "    img = initialize_image()\n",
        "    for iteration in range(iterations):\n",
        "        loss, img = learning_step(img, filter_index, model, learning_rate)\n",
        "    print (\"Training step {}, loss: {}\".format(iteration+1, loss))\n",
        "    # Decode the resulting input image\n",
        "    img = deprocess_image(img[0].numpy())\n",
        "    return loss, img"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLtOx9g4tVV3",
        "outputId": "0b953b42-90ff-461f-b0a4-864456ce06d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "#visualize number 4\n",
        "class_number = 4\n",
        "loss, img = visualize_filter(class_number, feature_extractor)\n",
        "keras.preprocessing.image.save_img(\"{}.png\".format(class_number), img)\n",
        "source = io.imread(\"{}.png\".format(class_number), as_gray=True)\n",
        "source = cv2.resize(source, (50, 50))\n",
        "plt.imshow(source, cmap='Greys')\n",
        "plt.show()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training step 100, loss: 5660.7119140625\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYLklEQVR4nO2dW6xe1XHH/xPbYIPxHXw5x65dMI0BcZEslAgeIlIkSlDgIaqCqopKCL+0ElFSBbeVKkXqA3nJRWqbyAoorhQFEkAC8VJR6ggFlTvYYCOwsbjY+IJv4As3w/ThbEdn//f47HX22d/37e+s/0+yfGZ7X2av74zXN7NmzZi7Qwgx/fnKoBUQQvQHGbsQmSBjFyITZOxCZIKMXYhMkLELkQlTMnYzu8nM3jCzXWa2sS2lhBDtY03X2c1sBoA3AdwIYA+A5wHc7u47JrhmWi3qm1ntOcpjEP3G3cNfzJlTuOe1AHa5+24AMLMHANwK4KzG3iXYUL/yleqXnDpjTjH2L774oiR/+eWXCdp1l+id+Rj/B9f0P7zoMxnPsI9lv5nK1/gRAO+Nk/cUx4QQHWQqM3sSZrYBwIZeP0cIMTFTMfa9AFaOk0eLYyXcfROATcBgffa6r+0pX09TGCYfvYnr0qv3i547TGM5DEzla/zzANaa2RozOwfAdwE81o5aQoi2aTyzu/tpM/sHAP8NYAaA+919e2uaCSFapfHSW6OHZfg1niPGXYog9+prfJNo/HR3mfrJ2ZbelEEnRCb0PBo/CKJZgmcxlmfOrB8KXjOPZpa21ph7AY/LjBkzKufMmjWrJLP+p0+frlzDx5rM5CkBui6N5TCimV2ITJCxC5EJMnYhMmFa+uwpvjRHxT///PNJ33fYfciU2Aa/Y5NVi2Efp+mCZnYhMkHGLkQmyNiFyIRp6bNHdClzrStE6+wM++NRPkJdlqB89m6gmV2ITJCxC5EJMnYhMkHGLkQmZBOgE2mcc845E8oRn332WUn++OOPJ5QjUhKhuswwbOzRzC5EJsjYhcgEGbsQmSCffUhpUsaJN7lESTWcNHPeeefV3pfv02RT0SCp87dTxjrlmpQSZb0cF83sQmSCjF2ITJCxC5EJMnYhMkEBuiGFg20pyS8cNJo9e3blHD7GAbsogFRXubdLRLrxMR6DaGzrqhFHVXg/+eSTCeWINgN23f1UhBCtImMXIhNk7EJkgnz2giaJE8O2eYP1nzNnTuWcuXPnlmT2VyM/k/1T7pzTT+o+xyiR6Nxzzy3JF1xwQUmOYhvss/MYROPE4/Lpp59WzlFSjRBiysjYhcgEGbsQmZCtz56ycYH9O+5wykUbgHh9tRfwJorI/2PYz4x89iVLlpRkHoMjR45UruHiFCm69Ar+HOvW0IFqnGLhwoUT/jtQ3ezD7xz53oMcF0AzuxDZIGMXIhNk7EJkQq2xm9n9ZnbQzF4bd2yRmT1hZjuLvxdOdA8hxOBJCdD9GsC/A/ivccc2AnjS3e81s42FfE/76vWPKEDHCSXnn39+SU7Z8HHy5MmSnJJskdKqqkmlUj4n0p+DdhycioKSTfRvQkpQld+Jg6pR5Z0FCxaU5MWLF094DwA4evRoSU7Z5MJj17nqsu7+FAAOwd4KYHPx82YAt7WslxCiZZouvS11933Fz/sBLD3biWa2AcCGhs8RQrTElNfZ3d3N7KzfR9x9E4BNADDReUKI3tLU2A+Y2XJ332dmywEcbFOpQRD5f7xBYv78+RPKQHUTxTvvvFOSDx8+XLmG/fp+tZeO3pkTb/h9WNeIXvmirG+0qYX9a/bhI5+dE4miz5XZv39/ST5x4sSEMlBNqul3G/GmS2+PAbij+PkOAI+2o44QolekLL39FsD/AfgLM9tjZncCuBfAjWa2E8BfFrIQosPUfo1399vP8k/fbFkXIUQPyXYjDBP5T7wuymunkW/Ha/GrVq0qyfPmzatcw2u2H374YUk+fvx45ZomBSLYl442ZvA48Do7r0FHx/g5kf/aBPbRo/HnOAv78NHmH/6cebNP1IWWz+F3TBnbfqN0WSEyQcYuRCbI2IXIBBm7EJmQbYAuZSMJB25OnTpVkqOqNLx5ZsWKFRPKQDXYw4k4/FygnQquUWtlDiJxQCsaJw7QpSSYpMBJNDy2UbCTj/E1KYFYDpBG+nNQNaVN9aDRzC5EJsjYhcgEGbsQmTBQnz2l+ACT0oWlrY0Y7Bdzcgv7bdGxa665piSPjIxUruGkjYsuuqgkf/DBB5Vr2M9PSdjgc6JkHd6ow2MQJZjwppCPPvqoVhcm+ty5EixvyomSanijCyfiRMku7G9zjKStpKZBo5ldiEyQsQuRCTJ2ITJh6Hz2yDftVbEE9svqfHig6kuzn7lu3brKNbxZgwtIPPPMM5VruIhE5EszPE5R8Uje7JPSuZbXpaP71hF97jx23Kkl8tn5Pvz7kpJPwWOZMrbDgGZ2ITJBxi5EJsjYhcgEGbsQmdC5AB0Hpzgo1jQYFz2rjrpnRckje/fuLckc3OFKKkC1uukll1xSki+99NLKNRwcjDqQsP48BlGnE05K4Uo1UbAqqvI6WSJdLrzwwpI8OjpakqNKsawfJwlFQVUOdvar7Xa/0cwuRCbI2IXIBBm7EJnQueIVnBTRrw0HTWIBkW9XV+CCYxJANTmEfdWoImp0nzbg+7I/HvnWXDCC/eaUJJsopsIbYbhyLxemiJ6VspGHi1MMQyGKJmhmFyITZOxCZIKMXYhM6Nw6e916eNOuGr3aLDPZ50bvxz45r8VH6/kp3VTrSCm+yHLks69cuXLCaw4cOFCrS/T5sO/MchTLYD8+pXgFb+QZdOeWXqGZXYhMkLELkQkydiEyQcYuRCb0PUA3PmkmCvZwUgcHS5pUQRkkHFRK2WTBAbqoIgsHp6JKt0xKy+aDBw+W5DfeeKMkRwknXF022pTDcOAsCrYtWrSoJHPlmpTEorpqQ2c7Nh3RzC5EJsjYhciEWmM3s5VmtsXMdpjZdjO7uzi+yMyeMLOdxd8L6+4lhBgcKT77aQA/cPeXzOwCAC+a2RMA/g7Ak+5+r5ltBLARwD0T3cjMSr5aVPSA/dVhKyRQV8E12ojBPiOPC2+MAaqVVt9///0p6wYA+/btK8lPPfVUSY4+j2PHjpXklKQU/py5SAYALFu2rCRzt9iouy0/m+MS0zVhJoXamd3d97n7S8XPxwG8DmAEwK0ANhenbQZwW6+UFEJMnUn57Ga2GsA1AJ4FsNTdz0wD+wEsbVUzIUSrJC+9mdlcAA8D+J67fzQ+x9vd3czC5HMz2wBgw1QVFUJMjaSZ3cxmYczQf+PujxSHD5jZ8uLflwM4GF3r7pvcfb27r29S9FEI0Q61M7uNWeh9AF5395+M+6fHANwB4N7i70fr7uXupQBJSrCEK4hG1Uk40aNJ++IowaTuPlHLIk70YN2iAB0Hq1avXl2S77rrrso1V155ZUmOWkS9+eabJfndd98tyVwJJoKDYClVbJko+YWDb1dccUXlnDVr1pRkTrzh9wGqO9i43XUbuwWHlZSv8dcB+FsAr5rZK8Wxf8aYkf/OzO4E8A6Av+6NikKINqg1dnf/I4Czff/+ZrvqCCF6hTLohMiEvm+EGZ9AEiVocIIJ+7NRFxD2t6ONDRwcTKkgWpfQE23k4ZgC+7jsUwJVfXkDyFVXXVW5Zvny5SX54osvrpzz9NNPl+TXXnutJEf6s747duwoyVHMgX1ylqM4C3e5ibrejIyMlGT+PKLPhzcEHTp0qCTnsuklQjO7EJkgYxciE2TsQmTCQKvLRv5TXUeVqAsqE61/s3/Ka8zc1QSo+pq8zhv53+zT8saSrVu3Vq7hLq7r1q0ryRdddFHlGi7kcP3111fO4bV4XnPevXt35ZpXX321JLP//fbbb1eu4eq33LmF3w8ALr/88pLMa+pA9bN/7733SvK2bdsq17B+OW98YTSzC5EJMnYhMkHGLkQmyNiFyISBBuii4AknyPAmi2jTRV1SB1Af6IuSdRYsWFCSOSgWJeYcP368JEebNRhOZHnrrbdKcpRUwwEtTrIBqu+0dGm55ADrClSDaymVbvk5XFGGq+pEx6Kg6uHDh0vynj17SnIULOSqOSlwwtWgWoX1Gs3sQmSCjF2ITJCxC5EJA/XZI9+I/Xj2i6NqN+yPp1TESdk8w3AsIKpuyok2nGRz5MiRyjU7d+4syVzRNfKT165dO6EMxBtd6nTh7i7bt28vyVGcgpN++LmRHtx5JmrrzAlJu3btKskpnWeYJm3Cp4sPr5ldiEyQsQuRCTJ2ITJhoD57BPtHKV1cU3x0vm9Kd0/2T1nmDSBAfYGFyM9vsjbMfv6KFSsq5/BmH97YExV/OHHiRElm3zrKYajrphr5+exvR4Ug+dm87j5sHX0HjWZ2ITJBxi5EJsjYhcgEGbsQmWD9TBg4Wz+4mmt6oUrSc/gYy9FGnn5VRuGNI1H76yZjVxcgjZ7D7ZZ580zUeYYDlVHgkuEgapRU02T8p9tGGHcPP3jN7EJkgoxdiEyQsQuRCZ332UW3iIpMsB/PG18iP79JF5+6eEJ0Tr9oK4ZS944p7yyfXYjMkbELkQkydiEyQT676Cxt5Fg08ZObwD56lFvA56QUYuFYRrT5h8+Rzy5E5sjYhcgEGbsQmVBr7GY228yeM7OtZrbdzH5UHF9jZs+a2S4ze9DMzqm7lxBicNQG6GwsinC+u58ws1kA/gjgbgDfB/CIuz9gZr8EsNXdf1Fzr9pISC6VPkWZKAmFO8twt5qoai2fw51noqo5vAmHKxBxAhBQX50nqgLEz07piFRXLYnvc/r06eYBOh/jTK2iWcUfB3ADgIeK45sB3FZ3LyHE4Ejy2c1shpm9AuAggCcAvAXgmLuf+e9rD4CRs1y7wcxeMLMX2lBYCNGMJGN39y/c/WoAowCuBfDV1Ae4+yZ3X+/u6xvqKIRogUlVl3X3Y2a2BcDXASwws5nF7D4KYO9kH55SMKJfPnq0wSOlg+x0oy5mEv173bikjFs0/ux/c6da7qoLVLvTLFu2rCRzhx6g6qNzVdujR4/W6sa+NFfCjZ4dJcjUJdXUdSie6PNLicZfaGYLip/nALgRwOsAtgD4TnHaHQAerbuXEGJwpMzsywFsNrMZGPvP4Xfu/riZ7QDwgJn9G4CXAdzXQz2FEFOk1tjdfRuAa4LjuzHmvwshhgBl0AmRCZ1r2dzknCZwEgdXRAWqwRIOwgxbwI6DN1FQjI/VtX0GquPA4xQlmDBRggm3lGb9OUgGAPPmzSvJq1atmvCe0bO5HVeU8MPXcCAteueUqjNMSpA49fdQM7sQmSBjFyITZOxCZMJAffaUpBomxT+J7sG+KLcvZjm6ps5PS9WvDVIqsLCvye8TJWhEfnzdc+uuaeqzc/tofp9Dhw5VrlmyZElJ3r9/f0k+fvx45RpOquHnRok4nBDD3WmibjV8TfTOPFZ8TjSW43/nJvr908wuRCbI2IXIBBm7EJkw0OqyKd1FUvxkJrrveeedV5J5XT1aT+b1YvbDoqIGKf5pG/A7Ru88Z86cCeXI/67rlBqtOXMl1ZMnT5Zk9oFTYf1SciNYF/7cozgFf/YpRSZYN74memce22gs2a9nuW6d3d1VXVaI3JGxC5EJMnYhMkHGLkQmDDSppp9wQIXlKAjDARU+p1fBzZTkFw5ORcEqPsb3iQKMde8YBZVSAn8MB/7qkkWic6JrODjIFWOiQCwH9Xj8U96HdYnGlonu28ZmmbOhmV2ITJCxC5EJMnYhMqFzxSuC9rOtPIvvG3XWYOqSavpVWCOqojp37tzac/id2Y+MfF4+h98xih+wLuzDR/EE9qWbJt5Mluid+/XsJrT5O6aZXYhMkLELkQkydiEyoXM+exNSCimyH8zXpHTdbINobZXXftkH5iKKQNUPjtZj6zakpBRYYKKx5U6p/D7R58z3ic5h/VI2QdUxbEVC20QzuxCZIGMXIhNk7EJkgoxdiEzo3EaYJgGUlKot0QaO8UTBn15sfEmpKMMJMosWLapcwwHFqGrqhx9+OKHchCjAOH/+/JLMAcWocm9dRRag2pmFq7xOpTtKjmhmFyITZOxCZIKMXYhM6JzP3oSUDf51xQQinzHlvnWwjx7FDjgJha+JEn64i0nUHSVKmpkqKYU0uKJr1G2Vu6tGRSWOHj1akrkDK2+mAarv3MZnOF3QzC5EJsjYhciEZGM3sxlm9rKZPV7Ia8zsWTPbZWYPmll1fUUI0Rkm47PfDeB1AGcWUX8M4Kfu/oCZ/RLAnQB+0bJ+SfDaauSnsc+eUnCyF+vqkW/KfjA/99SpU5VrUrqu9GLNOdocxPrVdd8Bqu8c5RLwWPFnFnVXZVK6u/SrkOigSZrZzWwUwLcA/KqQDcANAB4qTtkM4LZeKCiEaIfUr/E/A/BDAGf+C1wM4Ji7nwkT7wEwEl1oZhvM7AUze2FKmgohpkStsZvZLQAOuvuLTR7g7pvcfb27r29yvRCiHVJ89usAfNvMbgYwG2M++88BLDCzmcXsPgpgb+/UFEJMlUm1bDazbwD4R3e/xcx+D+DhcQG6be7+nzXXDyzyUdfVo1dVc3iTC3cfAeIA1niihCAOTqUEq9qAg28AsHjx4pLMSTRRUk1KdaG66rgcpATqu8akBDubdGXpEr1o2XwPgO+b2S6M+fD3TeFeQogeM6l0WXf/A4A/FD/vBnBt+yoJIXqBMuiEyIRpsREmhV4kSkRxgLpCGpFvynAiSJQwE22OmSwp3Ul53KLNNQcOHCjJnAyT0jk1imVwvIOLYERVd9nPZznayMPw+EeJRHWJOF308zWzC5EJMnYhMkHGLkQmZOOz94KUwpYsR9ewf8f+eEoxzBRS1rbrnhM9l31a1j/y83nNPDqHfX1e40/xv3nsUoqHcM5ClOdQVzAz8vMHvcFGM7sQmSBjFyITZOxCZIKMXYhMUIBuCqR0JElJfqkL0DUN7HBArk5uCuuXoi8HvaIgJFeX5SBeFGzjd0rRrY2EGNalraBqm0E9zexCZIKMXYhMkLELkQmTKl4x5YcNsHhFL2iyESaC/bu2NlHws1nfyOfl34de6ZZCXUwhZfz5nKijLCfVpPjwdclGUawmpYptk/hHcI/Wi1cIIYYIGbsQmSBjFyITZOxCZIICdFMgJSmlSTWYXlW6bZJU0+XWSE3GPwqY1rXVjp5TlzyVEnyLaGO8FaATInNk7EJkgoxdiEyQzy4EkeKzN0E+uxCiL8jYhcgEGbsQmaDiFUIQ7Dc3yZXoIprZhcgEGbsQmSBjFyITZOxCZIICdEIQvdqYNGg0swuRCTJ2ITJBxi5EJvTbZz8E4B0AS4qfh4Fh0hUYLn2HSVdgOPT9s7P9Q193vf3poWYvuPv6vj+4AcOkKzBc+g6TrsDw6cvoa7wQmSBjFyITBmXsmwb03CYMk67AcOk7TLoCw6dviYH47EKI/qOv8UJkQl+N3cxuMrM3zGyXmW3s57NTMLP7zeygmb027tgiM3vCzHYWfy8cpI5nMLOVZrbFzHaY2XYzu7s43lV9Z5vZc2a2tdD3R8XxNWb2bPE78aCZVTsvDggzm2FmL5vZ44XcWV1T6Juxm9kMAP8B4K8AXAbgdjO7rF/PT+TXAG6iYxsBPOnuawE8Wchd4DSAH7j7ZQC+BuDvi/Hsqr6fArjB3a8CcDWAm8zsawB+DOCn7n4JgKMA7hygjszdAF4fJ3dZ11r6ObNfC2CXu+92988APADg1j4+vxZ3fwrAETp8K4DNxc+bAdzWV6XOgrvvc/eXip+PY+yXcgTd1dfd/UQhzir+OIAbADxUHO+MvmY2CuBbAH5VyIaO6ppKP419BMB74+Q9xbGus9Td9xU/7wewdJDKRJjZagDXAHgWHda3+Fr8CoCDAJ4A8BaAY+5+pndSl34nfgbghwDO1KhajO7qmoQCdJPAx5YuOrV8YWZzATwM4Hvu/tH4f+uavu7+hbtfDWAUY9/0vjpglULM7BYAB939xUHr0ib9zI3fC2DlOHm0ONZ1DpjZcnffZ2bLMTYrdQIzm4UxQ/+Nuz9SHO6svmdw92NmtgXA1wEsMLOZxYzZld+J6wB828xuBjAbwDwAP0c3dU2mnzP78wDWFhHNcwB8F8BjfXx+Ux4DcEfx8x0AHh2gLn+i8CHvA/C6u/9k3D91Vd8LzWxB8fMcADdiLM6wBcB3itM6oa+7/5O7j7r7aoz9nv6vu/8NOqjrpHD3vv0BcDOANzHmq/1LP5+dqN9vAewD8DnGfLI7MearPQlgJ4D/AbBo0HoWul6Psa/o2wC8Uvy5ucP6Xgng5ULf1wD8a3H8zwE8B2AXgN8DOHfQupLe3wDw+DDoWvdHGXRCZIICdEJkgoxdiEyQsQuRCTJ2ITJBxi5EJsjYhcgEGbsQmSBjFyIT/h+r/y8XwU5D7gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0Ko9ndrZi-x"
      },
      "source": [
        "## Now visualize some filters of the convolutional layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASjiFQAiZpWT"
      },
      "source": [
        "#TODO"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OfAZkM47Ng9a"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}