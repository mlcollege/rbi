{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10-Transfer-learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOF_INxUcPLD"
      },
      "source": [
        "# Transfer Learning Task\n",
        "\n",
        "The goal of this task is to illustrate how pretrained neural networks can be used for soving different classification problems.\n",
        "\n",
        "## Data\n",
        "\n",
        "We will use the [Cifar 10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). It consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "Here are the classes in the dataset, as well as 10 random images from each:\n",
        "\n",
        "![cifar10](https://raw.githubusercontent.com/mlcollege/rbi/master/specializations/Deep-Learning/src/images/cifar10.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70eKVSd3Bcev"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from tensorflow.python.keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKgE-SjNC5Do"
      },
      "source": [
        "Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8lqSW6OC8Gs"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "import numpy as np\n",
        "\n",
        "n_classes = 10\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "x_train_mean = np.mean(x_train, axis=0)\n",
        "x_train -= x_train_mean\n",
        "x_test -= x_train_mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1v5qOMsDgow"
      },
      "source": [
        "Import pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXlt7ntQCpc4"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from tensorflow.keras.applications import VGG16\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "for layer in base_model.layers[:-4]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZIpQiXwDyQ_"
      },
      "source": [
        "Add new top layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZsaIchIP6wa"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from tensorflow.python.keras import models, layers\n",
        "    \n",
        "model = models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlN-7FUqEGEf"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joNSbPVxQwL_"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3VgPkmaKyMK"
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size = 512, epochs = 20, verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAMR2Y-4Fc1r"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "First we need to convert probability vectors to class indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx9BF4owRQLw"
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "\n",
        "print(y_pred.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fkgj0CsFiKf"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "y_test_class = np.argmax(y_test, axis=1)\n",
        "y_pred_class = np.argmax(y_pred, axis=1)\n",
        "print(y_pred_class.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hJX2LzCFqH3"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "print (\"Test accuracy: {:.4f}\".format(accuracy_score(y_test_class, y_pred_class)))\n",
        "print ()\n",
        "print(metrics.classification_report(y_test_class, y_pred_class, digits=4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsyQZar3Fw5F"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(confusion_matrix(y_test_class, y_pred_class))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}